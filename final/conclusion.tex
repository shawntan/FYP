\chapter{Conclusion}

% Jesse: I think you could use several sentences to remind the reader that
% this is 1) challenging and 2) important problem. A conclusion should provide
% a concise message that you want your reader to remember about the entire
% report. So, what is it that you really want your reader to remember? Notice how
% this is different from merely summarizing your thesis or rephrasing your
% introduction.
With the increasing number of sites leveraging user-generated content, a method 
for predicting the updates of such sites needs to be created in order for an 
incremental web crawler to effectively crawl the site. Our high level goal: to 
predict the posting behaviour of users to such sites.

While this primary goal has many challenges, in this report, we have chosen to 
address challenges specific to forum threads. We want to predict, given content 
of the current thread, the time at which a user would post to the thread. We 
also need to ensure that bandwidth consumption is not excessive in the process 
maintaining the freshness of the crawled data.

We evaluate three different machine learning approaches: Two offline algorithms, 
one that only takes into account only the latest window, and another that 
accounts for past windows, with decreasing weightage. And an online algorithm, 
that uses gradient descent to update its weights every time a new post is 
observed.

Overall, our evaluation shows that our methods work better than the baseline, 
which was to revisit the thread at the average time interval. These are 
promising results, and more can be done to improve upon them. 

\section{Contributions}
We have made the following contributions with our work:
\begin{enumerate}
\item Provided evaluation metrics that can be parameterised, depending on the 
	evaluators' priority: freshness or bandwidth. The metric allows for an easy 
	way to compare the performance of two models.

\item Proposed three different methods that can be employed for making revisit 
time estimations. These methods perform significantly better than the baseline.  
We also made recommendations on how they can be used in a web crawler.  

\item Showed that using content as part of the feature set contributes to a 
better model for estimating posting times.
\end{enumerate}

\section{Future Work}
With the proposed methods still having some shortcomings when predicting new 
posts, or providing insight into what causes post arrival times, it leaves much 
room for future work to be done.

\subsection{Topic modelling}
One approach we initially considered involved using topic modelling did not pan 
out due to time constraints (See Appendix \ref{top_modeling}). This approach 
involved modeling the process of thread posts as a Hidden Markov Model, with 
topics as the hidden states, producing words and a distribution of time 
differences. Some work already exists that use HMMs for prediction of data like 
stock price predictions \cite{Gonzalez2005} and using HMMs together with LDA for 
making better predictions of language models \cite{Hsu2006}.

\subsection{Using Natural Language Processing (NLP) techniques}
An improvement could be made to the feature set used in our project. A source 
for features that could be useful may be found in \outcite{Wang}. Since their 
work aims to predict retweetability of tweets, the same features being 
considered could also play a role in determining when a new post is made.

\subsection{Leveraging context}
One of the assumptions made in selecting the feature set as we did, was that the 
thread was self-contained: the content of the thread will affect the rate of 
posting. However, we know this is not true, since news regarding a certain 
product may affect a discussion thread of said product.

If some data from recent news could be factored into the features, this may lead 
to a better prediction of post arrival times.

\subsection{Using adaptive learning techniques}
An interesting approach to forecasting stock prices was presented in 
\outcite{Cao2003}. The technique involved tweaking conventional SVMs to weigh 
recent training instances more heavily than older instances. This is a 
particularly useful idea, since we face the same issue in our task: Recent posts 
are more descriptive of the current state of the thread, and hence should be 
more useful in predicting the next post.
