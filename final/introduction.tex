\chapter{Introduction}

With the advent of Web 2.0, sites with forums, or similar thread-based
discussion features are increasingly common.  Table \ref{table:web20} shows us 
that many of the popular Web 2.0 sites have comment features. This suggests that 
content on the web is increasingly being created by users alongside content 
providers. Our goal in this thesis is to create an algorithm that can predict 
when updates in such discussion threads will occur.

\begin{table}
	\makebox[\textwidth][c]{
	{\footnotesize
	\begin{tabular}{|l|c|c|c|c|c|c|c|c|c|c|}
		\hline
			\input{tables/web20}
		\hline
	\end{tabular}
	~\\
	}
	}
	{\footnotesize
\caption{Features of popular Web 2.0 sites}
\label{table:web20}
	\begin{tabular}{l l}
		T &= Twitter mentions\\
	 FB L &= Facebook Likes \\
		FB S &= Facebook Shares\\
	G +1 &= Google +1\\
		   L&= Likes (Local) \\
   		DL &= Dislikes (Local) \\
			C &= Comments \\
		PV &= Page Views \\
   Follows &= Site-local feature for keeping track of user's activities
	\end{tabular}
}
\end{table}

A naive way of getting timely updates would be to aggressively hit the pages 
repeatedly (polling), downloading pages at a frequent rate. Since web crawling 
is largely IO-bound, a large portion of the time spent crawling would be spent 
waiting for the server to supply a response to the request issued by the 
crawler. However, sites with a large number of pages (like popular forum sites), 
makes this infeasible in practice. On top of the usual requests the server may 
have, it then has to deal with repeated requests from such a crawler. Most sites 
do not mind some additional bandwidth, but if it gets excessive, it may be 
construed as a Denial-of-Service attack. These sites may then deny any further 
requests from the crawler.

A simple method to reduce the amount of polling done is to use the
average time differences between all of the previous page updates to estimate 
the arrival of the next update, and to abstain from polling until the
estimated time.
%This is a metric that performs reasonably well according to 

%Min: you need to discuss how well this simple baseline does and whether it is 
%actually adopted.
% Jesse: agreed. please remember to include the results for this baseline in
% the experiment section.

A key observation in our work is that the contents of the thread may
also influence the discussion and hence the rate of commenting. For example, a 
thread in a technical forum about a Linux distribution may start out as a 
question. Subsequent questions that attempt to either clarify or expand on the 
original question may then be posted, resulting in a quick flurry of messages.  
Eventually, a more technically savvy user of the forum may come up with a 
solution, and the thread may eventually slow down after a series of messages 
thanking the problem solver. We believe that the content of the thread has 
information that can give a better estimate of the time interval between the 
last post and a new one.

% Min: tie the ``hypothetical'' example with actual posts.  Also, your
% introduction needs to actually carry through to the final
% implementation and experimentation where you use such features to
% estimate properly.
% Jesse: The paragraph below comes too late. The doubt in the reader's mind
% appears immediately after reading "A key observation...", but you only
% mention this example one paragraph later. If you follow Min's suggestion and
% use actual posts, you can refer make label those posts with figure numbers
% and refer to the posts in the text.




Let us define all such thread-based discussion styled sites as forums. Ideally, 
an incremental crawler of such user-generated content should be able to maintain 
a fresh and complete database of content of the forum that it is monitoring.  
However, doing so with the previously mentioned naive method would, incur 
excessive costs when downloading un-updated pages, and raise the possibility of 
the web master blocking the requester's IP address.

% Jesse: You need to make a better transition to the next paragraph. How does
% this situation lead you to have the following goal? 
As such, we need to have a way to achieve a balance between two things: (1) 
Reduce the requests made, and (2), still be able to retrieve updates in a timely 
fashion. There has been work done (see Chapter 2) in this respect, but we argue 
that existing content should be included into any model that attempts to predict 
updates to user-generated content.

Our high level goal: To devise a suitable algorithm for predicting new posts in 
user discussion threads, based on the discussion content in the thread. In this 
project, we focus on forum threads, and make the following contributions:
\begin{enumerate}
	\item We demonstrate three different methods for achieving this using 
regression methods.
	\item We propose a novel metric for measuring the timeliness of such a model 
that balances between the model's timeliness and bandwidth consumption.
\end{enumerate}
% Jesse: You are burying the lead. It seems to me that you have major
% contributions in this thesis, but you are hiding them inside this tiny
% little paragraph. Make them stand-out. Use a numbered list. Make it clear
% that these are your contributions, especially if they are novel. And if they
% are, you should mention that they're novel whenever appropriate.

In Chapter 2, we explore the related work dealing with refresh policiesand 
metrics to measure the performance of such algorithms. In Chapter 3, we discuss 
the methods that we have created with to tackle the problem, while Chapter 4 
describes the metrics we propose for measuring the performance of these 
algorithms.  In Chapter 5, we perform experiments on a dataset extracted from 
\url{avsforum.com}, 
% Jesse: you could mention a little more about the significance of the results
% and the size of the data set here.
and show that our models perform better than 
an average revisitation baseline. Chapter 6 then discusses our contributions, 
and possible avenues of future work.
